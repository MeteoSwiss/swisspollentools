{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SwissPollenTools | Inference Pipeline Example\n",
    "\n",
    "1. Loading the tools\n",
    "2. Creating the pipeline configuration\n",
    "3. Creating the pipeline\n",
    "4. Running the inference pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swisspollentools.pipelines import InferencePipelineConfig, InferencePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Keras Model\n",
    "> Note that implementing a new model, it is preferable to implement the respective postprocessing function and to provide it with the model.\n",
    "\n",
    "For demonstration purposes, we implement a random model and we design a postprocessing function associated with it. \n",
    "In an operational setup, the model would be loaded using the `keras.models.load_model` command and the post processing function would be implemented (copied) from the inference script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RandomModel():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, batch, *args, **kwargs):\n",
    "        return np.random.random((len(batch[\"rec0\"]), 8))\n",
    "    \n",
    "def post_processing_fn(batch):\n",
    "    predicted_class = np.argmax(batch, axis=-1)\n",
    "    predicted_certainity = np.max(batch, axis=-1)\n",
    "    return {\n",
    "        \"class\": predicted_class,\n",
    "        \"certainity\": predicted_certainity\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the pipeline configuration\n",
    "\n",
    "### Extraction Tool Parameters\n",
    "- `exw_batch_size`\n",
    "- `exw_keep_metadata`\n",
    "- `exw_keep_fluorescence`\n",
    "- `exw_keep_rec_properties`\n",
    "- `exw_keep_metadata_key`\n",
    "- `exw_keep_fluorescence_keys`\n",
    "- `exw_keep_rec_properties_keys`\n",
    "- `exw_filters`\n",
    "### Inference Tool Parameters\n",
    "- `inw_from_rec0`\n",
    "- `inw_from_rec1`\n",
    "- `inw_from_fluorescence`\n",
    "- `inw_from_fluorescence_keys`\n",
    "- `inw_rec_shape`\n",
    "- `inw_rec_precision`\n",
    "- `inw_batch_size`\n",
    "- `inw_post_processing_fn`\n",
    "### ToCSV Tool Parameters\n",
    "- `tocsvw_output_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = InferencePipelineConfig(\n",
    "    exw_batch_size=1024,\n",
    "    exw_keep_metadata_key=[\"eventId\"],\n",
    "    exw_keep_fluorescence_keys=[\"average_std\", \"average_mean\", \"relative_spectra\"],\n",
    "    exw_filters={\"max_area\": 625, \"max_solidity\": 0.9},\n",
    "    inw_from_fluorescence=False,\n",
    "    inw_batch_size=256,\n",
    "    inw_post_processing_fn=post_processing_fn,\n",
    "    tocsvw_output_directory=\"./tmp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = InferencePipeline(config, inw_model=RandomModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    out = pipeline(file_path=\"./path/to/example.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendice A: Implementing the Inference Pipeline with a Merge Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from swisspollentools.utils import *\n",
    "from swisspollentools.workers import ExtractionWorkerConfig, \\\n",
    "    InferenceWorkerConfig, MergeWorkerConfig, ToCSVWorkerConfig, \\\n",
    "    ExtractionRequest, ZipExtraction, InferenceRequest, Inference, \\\n",
    "    MergeRequest, Merge, ToCSVRequest, ToCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the pipeline configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exw_config = ExtractionWorkerConfig(\n",
    "    exw_batch_size=1024,\n",
    "    exw_keep_metadata_key=[\"eventId\"],\n",
    "    exw_keep_fluorescence_keys=[\"average_std\", \"average_mean\", \"relative_spectra\"],\n",
    "    exw_filters={\"max_area\": 625, \"max_solidity\": 0.9},\n",
    ")\n",
    "inw_config = InferenceWorkerConfig(\n",
    "    inw_from_fluorescence=False,\n",
    "    inw_batch_size=256,\n",
    "    inw_post_processing_fn=post_processing_fn,\n",
    ")\n",
    "mew_config = MergeWorkerConfig()\n",
    "tocsvw_config = ToCSVWorkerConfig(\n",
    "    tocsvw_output_directory=\"./tmp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergedInferencePipeline(config, **kwargs):\n",
    "    exw_config, inw_config, mew_config, tocsvw_config = config\n",
    "    exw_kwargs = get_subdictionary(kwargs, EXTRACTION_WORKER_PREFIX, ATTRIBUTE_SEP)\n",
    "    inw_kwargs = get_subdictionary(kwargs, INFERENCE_WORKER_PREFIX, ATTRIBUTE_SEP)\n",
    "    mew_kwargs = get_subdictionary(kwargs, MERGE_WORKER_PREFIX, ATTRIBUTE_SEP)\n",
    "    tocsvw_kwargs = get_subdictionary(kwargs, TOHDF5_WORKER_PREFIX, ATTRIBUTE_SEP)\n",
    "\n",
    "    def run(file_path):\n",
    "        out = ExtractionRequest(file_path=file_path)\n",
    "        out = ZipExtraction(out, exw_config, **exw_kwargs)\n",
    "        out = (InferenceRequest(file_path, batch_id, response=el) for batch_id, el in enumerate(out))\n",
    "        out = (Inference(el, inw_config, **inw_kwargs).__next__() for el in out)\n",
    "        out = (MergeRequest(file_path, None, el) for el in out)\n",
    "        out = Merge(list(out), mew_config, **mew_kwargs)\n",
    "        out = [ToCSVRequest(file_path, None, response=out)]\n",
    "        out = (ToCSV(el, tocsvw_config, **tocsvw_kwargs).__next__() for el in out)\n",
    "\n",
    "        return list(out)\n",
    "    \n",
    "    return run\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MergedInferencePipeline(\n",
    "    (exw_config, inw_config, mew_config, tocsvw_config),\n",
    "    inw_model=RandomModel()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    out = pipeline(file_path=\"./path/to/example.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
